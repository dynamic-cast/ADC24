{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64098597-7bcb-46fc-a999-3c9f5e5c213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1: embedding a trained generative AI model into a music app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9484a3-5fe1-4601-98af-19910757550b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The provided filename path/to/rave-model does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_audio_engine\n",
      "File \u001b[0;32m~/code/ADC24/app/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m, instance_relative_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m socketio \u001b[38;5;241m=\u001b[39m SocketIO(app)\n\u001b[0;32m----> 8\u001b[0m \u001b[43msetup_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocketio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;129m@app\u001b[39m\u001b[38;5;241m.\u001b[39mroute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindex\u001b[39m():\n\u001b[1;32m     12\u001b[0m     reset_audio_engine(current_app\u001b[38;5;241m.\u001b[39maudio_engine)\n",
      "File \u001b[0;32m~/code/ADC24/app/app_utils.py:15\u001b[0m, in \u001b[0;36msetup_app\u001b[0;34m(app, socketio)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# BODGE!\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# app.latent_coordinates = Queue(maxsize=1)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m audio_engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_audio_engine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mINPUT_WAV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMODEL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# app.latent_coordinates,\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m audio_engine\u001b[38;5;241m.\u001b[39mstop\u001b[38;5;241m.\u001b[39mset()\n\u001b[1;32m     21\u001b[0m app\u001b[38;5;241m.\u001b[39maudio_engine \u001b[38;5;241m=\u001b[39m audio_engine\n",
      "File \u001b[0;32m~/code/ADC24/app/audio/__init__.py:4\u001b[0m, in \u001b[0;36mcreate_audio_engine\u001b[0;34m(input_wav, model_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_audio_engine\u001b[39m(input_wav, model_path):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAudioEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_wav\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/ADC24/app/audio/engine.py:48\u001b[0m, in \u001b[0;36mAudioEngine.__init__\u001b[0;34m(self, input_wav, model_path, *a, **k)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_position \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zeros \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_size, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_type)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rave_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample\u001b[38;5;241m.\u001b[39msampling_rate \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rave_model\u001b[38;5;241m.\u001b[39msampling_rate:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling rates differ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/ADC24/app/audio/rave.py:42\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(path):\n\u001b[0;32m---> 42\u001b[0m     script_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RaveModelRepresentation(script_module)\n",
      "File \u001b[0;32m~/code/ADC24/workshopenv/lib/python3.12/site-packages/torch/jit/_serialization.py:149\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, _extra_files, _restore_shapes)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(f):  \u001b[38;5;66;03m# type: ignore[type-var]\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided filename \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore[str-bytes-safe]\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(f):\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided filename \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is a directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore[str-bytes-safe]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The provided filename path/to/rave-model does not exist"
     ]
    }
   ],
   "source": [
    "from app.audio import create_audio_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763297b-99ec-43be-ba01-1a5074f7fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df262800-fe10-4e6a-9fe3-b15aad321df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://play.forum.ircam.fr/rave-vst-api/get_model/darbouka_onnx\", \"darbouka_onnx.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b04a6a-9569-413b-ad53-b4305970a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine = create_audio_engine(\"test-loop.wav\", \"darbouka_onnx.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49914dc7-65b8-45b6-a16e-39bd7686d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b66b61-b5da-4b2a-9085-3ce3ed711e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.loop.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891d4c1-2543-46e3-8c5d-b04ca45e3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.transform.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fb456-019b-4916-a053-e354ad068e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.set_latent_coordinates([0.1, 0.1, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f1fd8-229a-44bc-86c8-46d95de7f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.transform.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b792e-d2f6-4772-b0b3-1ba4106bb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.stop.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f51975-188c-422e-8fae-e826d47d0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.stop.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556731b4-2ff2-450a-a754-64596892821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2: Training a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee82199-0231-48c2-ac6e-90b9a2c13245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from app.control.xy import Model, XYControl, Mode\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe962e26-14b8-4c9e-8aca-0c7d1911b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f09ad-4f1a-4411-803d-42a180a51a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 4),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809aef69-59d3-449f-a027-aff9a41a7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a24afe-c4ad-4d4b-b4b1-55c1bd7e1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control = XYControl(audio_engine.set_latent_coordinates, None, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7833c-a62c-4fb4-8be7-df5976dc65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433371ae-a920-43a3-8ceb-ce4cffb947f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = xy_control._prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cf640-2e64-4084-8c2d-bcc6d7c20a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control._initialize_training_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554b969-c78d-4ad8-bc6d-b1b4630b9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mse = np.inf # init to infinity\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b803c-5f2c-4a4c-9cb5-27ca464f1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(X_train, y_train):\n",
    "        running_loss = 0.0\n",
    "        batch_start = torch.arange(0, len(X_train), xy_control.batch_size)\n",
    "        xy_control._model.train()\n",
    "\n",
    "        for start in batch_start:\n",
    "            X_batch = X_train[start:start+xy_control.batch_size]\n",
    "            y_batch = y_train[start:start+xy_control.batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = xy_control._model(X_batch)\n",
    "            loss = xy_control.loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            xy_control.optimiser.zero_grad()\n",
    "            if not loss.requires_grad:\n",
    "                loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            xy_control.optimiser.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        return running_loss / len(batch_start)  # Average loss per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d96900-649b-4db7-a02d-3ecc3609a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(xy_control.n_epochs): # n_epochs = 100\n",
    "    running_loss = train_one_epoch(X_train, y_train)\n",
    "    \n",
    "    # evaluate accuracy at end of each epoch\n",
    "    mse = xy_control._validate(X_test, y_test)\n",
    "    history.append(mse)\n",
    "    \n",
    "    # Save best model if improved\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        xy_control._model_weights = copy.deepcopy(xy_control._model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dbb6f-17c3-4f70-afa1-a1dea411c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control._model_trained = True\n",
    "xy_control._mode =  Mode.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5d9e2-8853-4e2d-a18f-04e1504b78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control.receive_coordinates([0, 0], [1, 2, 3, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshopenv",
   "language": "python",
   "name": "workshopenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
