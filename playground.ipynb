{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64098597-7bcb-46fc-a999-3c9f5e5c213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1: embedding a trained generative AI model into a music app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9484a3-5fe1-4601-98af-19910757550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.audio import create_audio_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763297b-99ec-43be-ba01-1a5074f7fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df262800-fe10-4e6a-9fe3-b15aad321df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://play.forum.ircam.fr/rave-vst-api/get_model/darbouka_onnx\", \"darbouka_onnx.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b04a6a-9569-413b-ad53-b4305970a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine = create_audio_engine(\"test-loop.wav\", \"darbouka_onnx.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49914dc7-65b8-45b6-a16e-39bd7686d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b66b61-b5da-4b2a-9085-3ce3ed711e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.loop.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891d4c1-2543-46e3-8c5d-b04ca45e3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.transform.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303fb456-019b-4916-a053-e354ad068e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.set_latent_coordinates([0.1, 0.1, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f1fd8-229a-44bc-86c8-46d95de7f47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.transform.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b792e-d2f6-4772-b0b3-1ba4106bb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.stop.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f51975-188c-422e-8fae-e826d47d0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_engine.stop.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556731b4-2ff2-450a-a754-64596892821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2: Training a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee82199-0231-48c2-ac6e-90b9a2c13245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from app.control.xy import Model, XYControl, Mode\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe962e26-14b8-4c9e-8aca-0c7d1911b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f09ad-4f1a-4411-803d-42a180a51a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 4),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809aef69-59d3-449f-a027-aff9a41a7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a24afe-c4ad-4d4b-b4b1-55c1bd7e1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control = XYControl(audio_engine.set_latent_coordinates, None, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7833c-a62c-4fb4-8be7-df5976dc65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433371ae-a920-43a3-8ceb-ce4cffb947f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = xy_control._prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621cf640-2e64-4084-8c2d-bcc6d7c20a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control._initialize_training_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554b969-c78d-4ad8-bc6d-b1b4630b9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mse = np.inf # init to infinity\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b803c-5f2c-4a4c-9cb5-27ca464f1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(X_train, y_train):\n",
    "        running_loss = 0.0\n",
    "        batch_start = torch.arange(0, len(X_train), xy_control.batch_size)\n",
    "        xy_control._model.train()\n",
    "\n",
    "        for start in batch_start:\n",
    "            X_batch = X_train[start:start+xy_control.batch_size]\n",
    "            y_batch = y_train[start:start+xy_control.batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = xy_control._model(X_batch)\n",
    "            loss = xy_control.loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            xy_control.optimiser.zero_grad()\n",
    "            if not loss.requires_grad:\n",
    "                loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            xy_control.optimiser.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        return running_loss / len(batch_start)  # Average loss per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d96900-649b-4db7-a02d-3ecc3609a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(xy_control.n_epochs): # n_epochs = 100\n",
    "    running_loss = train_one_epoch(X_train, y_train)\n",
    "    \n",
    "    # evaluate accuracy at end of each epoch\n",
    "    mse = xy_control._validate(X_test, y_test)\n",
    "    history.append(mse)\n",
    "    \n",
    "    # Save best model if improved\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        xy_control._model_weights = copy.deepcopy(xy_control._model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dbb6f-17c3-4f70-afa1-a1dea411c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control._model_trained = True\n",
    "xy_control._mode =  Mode.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5d9e2-8853-4e2d-a18f-04e1504b78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_control.receive_coordinates([0, 0], [1, 2, 3, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshopenv",
   "language": "python",
   "name": "workshopenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
